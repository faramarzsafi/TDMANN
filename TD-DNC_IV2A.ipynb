{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_g2Ss23Gvrni"
   },
   "outputs": [],
   "source": [
    "basePath='D:\\\\PM2\\\\IV2A_TD-DNC\\\\'\n",
    "dbType='IV2A_Imagery'\n",
    "random_seed = 32654\n",
    "\n",
    "Channels=3\n",
    "features=1000\n",
    "nb_classes=2\n",
    "batch_size=512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "1EODUBQj-zPU"
   },
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true,
    "id": "Cnx3rIkH6WJc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "id": "VfE76Qxz9l_h",
    "outputId": "947b8072-692f-4ecf-f618-73267cd04ede",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import os,sys,inspect,glob,warnings\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "sys.path.insert(0,'D:\\\\PM2\\\\')\n",
    "\n",
    "\n",
    "print('**** ok ****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "id": "IfQXvs0jvxQv",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "ghjk\n",
    "\n",
    "\n",
    "#!pip uninstall tensorflow==2.2.0 --yes\n",
    "pip uninstall keras --yes\n",
    "\n",
    "      #!pip install argcomplete\n",
    "pip install keras==2.2.4\n",
    "#!pip install tensorflow==1.10\n",
    "\n",
    "\n",
    "\n",
    "pip install ipython-autotime\n",
    "pip install plot_keras_history\n",
    "\n",
    "print('~'*50)\n",
    "\n",
    "\n",
    "%tensorflow_version 1.10\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "print('~'*50)\n",
    "\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "id": "u1chUhOulg1X",
    "outputId": "fc59a3be-6cae-4e59-fe20-4cbce566eeff",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 1.10\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "h11kVYItZ-qn"
   },
   "source": [
    "## Prepare Data 25920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "btEKncbgaFz0",
    "outputId": "38de573d-7678-4a10-ce59-7971dbccbb71"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import gc\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "  #~~~~~~~~~~~~~~~~~~~~~~~~~~~     prepare data   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "  \n",
    "\n",
    "  with open('D:\\ds\\MMCNN_2A_data_raw.pkl','rb') as f: #read\n",
    "    _Data = pkl.load(f)\n",
    "  \n",
    "  print(_Data.shape)\n",
    "  print('-------------------------------------------')\n",
    "\n",
    "\n",
    "  with open('D:\\ds\\MMCNN_2A_label_raw.pkl','rb') as f: #read\n",
    "    _Target = pkl.load(f)\n",
    "  \n",
    "  print(_Target.shape)\n",
    "  print('-------------------------------------------')\n",
    "\n",
    "\n",
    "  _Data = _Data.reshape( _Data.shape[0] , 1000 * 3 )\n",
    "\n",
    "  print(' _Data shape is : ' , _Data.shape)\n",
    "  print(' _Target shape is : ' , _Target.shape)\n",
    "  \n",
    "\n",
    "  return _Data, _Target\n",
    "\n",
    "\n",
    "\n",
    "_Data, _Target= prepare_data()\n",
    "print(' Load data ==> OK  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "bV9_BW3paQiN",
    "outputId": "fea13d64-d578-4fee-86bc-f49e467767b9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_and_prepare_Data(_Data, _Target):\n",
    "  X_train, X_test, y_train, y_test = train_test_split( _Data, _Target , test_size=0.3 , random_state=random_seed  , shuffle=True)  #276159\n",
    "\n",
    "\n",
    "\n",
    "  print(\"\\x1b[31m  ....................................  \\x1b[0m\")\n",
    "  print('X_train: ', X_train.shape)\n",
    "  print('X_test: ', X_test.shape)\n",
    "  print('y_train: ', y_train.shape)\n",
    "  print('y_test: ', y_test.shape)\n",
    "  print(\"\\x1b[31m  ................. Total ...................  \\x1b[0m\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  X_train=X_train[:15360]\n",
    "  y_train=y_train[:15360]\n",
    "\n",
    "  X_test=X_test[:7168]\n",
    "  y_test=y_test[:7168]\n",
    "  \n",
    "\n",
    "\n",
    "  print()\n",
    "  print(\"\\x1b[31m  .................. Summary ..................  \\x1b[0m\")\n",
    "  print('X_train: ', X_train.shape)\n",
    "  print('X_test: ', X_test.shape)\n",
    "  print('y_train: ', y_train.shape)\n",
    "  print('y_test: ', y_test.shape)\n",
    " \n",
    "\n",
    "  print(\"\\x1b[31m  ....................................  \\x1b[0m\")\n",
    "\n",
    "\n",
    "\n",
    "  import pickle as pkl\n",
    "  with open(basePath+'Imagery_temp_X_test_IV2A.pkl','wb') as f: #write\n",
    "    pkl.dump( X_test , f)\n",
    "\n",
    "  with open(basePath +'Imagery_temp_y_test_IV2A.pkl','wb') as f: #write\n",
    "    pkl.dump( y_test , f)\n",
    "\n",
    "  del  X_test, y_test\n",
    "\n",
    "\n",
    "  return X_train,y_train\n",
    "\n",
    "\n",
    "X_train, y_train= split_and_prepare_Data(_Data, _Target)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "WH6ViNM0aWdo"
   },
   "outputs": [],
   "source": [
    "del _Data, _Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "2lSAgSfcaZUJ",
    "outputId": "21271d1b-597f-4052-cea2-b8a0b369ec28"
   },
   "outputs": [],
   "source": [
    "print( X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "UZdbvnLQy8Tw"
   },
   "outputs": [],
   "source": [
    "y_train2=[np.where(r==1)[0][0] for r in np.array( y_train ) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "aTb_J9rhuBs6"
   },
   "source": [
    "## Reshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "id": "q-uEtXfXB8XR"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator , TransformerMixin\n",
    "\n",
    "class CustomLSTMReshaper(BaseEstimator , TransformerMixin):\n",
    "    \n",
    "     def fit(self,X,y=None):\n",
    "        return self    \n",
    "    \n",
    "     def transform(self, X, y=None):     \n",
    "        return X.reshape(( len(X), features, Channels ,1 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "JiZUQk7CYqN0"
   },
   "source": [
    "## Train Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "2hBfOO0IYpNL",
    "outputId": "64db53e7-1cae-411a-a35d-8e9209b64ec6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "# https://medium.com/@mostafa.m.ayoub/customize-your-keras-metrics-44ac2e2980bd\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred) #precision_m\n",
    "    recall = recall_m(y_true, y_pred) #recall_m\n",
    "    return 2*( (precision*recall)/(precision+recall+K.epsilon() )   )\n",
    "\n",
    "\n",
    "def specificity_m(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "\n",
    "# implement at: https://www.sabinasz.net/unbalanced-classes-machine-learning/\n",
    "def sensitivity_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "Fjo7iI5D3Rt8"
   },
   "source": [
    "## Test Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "id": "i2PvngAx3S3j"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Metric library\n",
    "from imblearn.metrics import sensitivity_score ,specificity_score #geometric_mean_score\n",
    "\n",
    "from sklearn.metrics import(\n",
    "                            accuracy_score,\n",
    "                            precision_score, \n",
    "                            recall_score,\n",
    "                            f1_score,                                                      \n",
    "                            make_scorer,                            \n",
    "                            cohen_kappa_score\n",
    "                            )\n",
    "\n",
    "\n",
    "def make_experiments_for_tuner():\n",
    "       \n",
    "    accuracy = make_scorer(accuracy_score)\n",
    "    precision = make_scorer(precision_score , average = 'macro' )\n",
    "    recall = make_scorer(recall_score , average = 'macro')\n",
    "    f1 = make_scorer(f1_score  , average = 'macro')\n",
    "    sensitivity = make_scorer( sensitivity_score  , average = 'macro')     \n",
    "    specificity = make_scorer( specificity_score , average = 'macro')\n",
    "    kappa= make_scorer(cohen_kappa_score   )\n",
    "\n",
    "    scores_for_grid = {\n",
    "    \"accuracy\":accuracy,\n",
    "    \"precision\":precision, \n",
    "    \"recall\":recall,\n",
    "    \"f1\":f1,\n",
    "    \"sensitivity\":sensitivity,\n",
    "    \"specificity\":specificity,\n",
    "    \"kappa\":kappa\n",
    "    }\n",
    "    \n",
    "    return scores_for_grid\n",
    "\n",
    "\n",
    "def get_experiments(true_label,pred_label):\n",
    "    \n",
    "     return  {\n",
    "    \"test_accuracy\":accuracy_score(true_label,pred_label ),\n",
    "    \"test_precision\":precision_score(true_label,pred_label , average='macro' ), \n",
    "    \"test_recall\":recall_score(true_label,pred_label , average='macro' ),\n",
    "    \"test_f1\":f1_score(true_label,pred_label , average='macro' ),\n",
    "    \"test_specificity\":specificity_score(true_label,pred_label , average='macro'),    \n",
    "    \"test_sensitivity\":sensitivity_score(true_label,pred_label , average='macro'),\n",
    "    \"test_kappa\":cohen_kappa_score(true_label,pred_label   )\n",
    "     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "0NvX4TCiB3Zs"
   },
   "source": [
    "## model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# need these for ShallowConvNet\n",
    "def square(x):\n",
    "    return K.square(x)\n",
    "\n",
    "def log(x):\n",
    "    return K.log(K.clip(x, min_value = 1e-7, max_value = 10000)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def ShallowConvNet(nb_classes, Chans = 64, Samples = 128, dropoutRate = 0.5):\n",
    "    \"\"\" Keras implementation of the Shallow Convolutional Network as described\n",
    "    in Schirrmeister et. al. (2017), Human Brain Mapping.\n",
    "    \n",
    "    Assumes the input is a 2-second EEG signal sampled at 128Hz. Note that in \n",
    "    the original paper, they do temporal convolutions of length 25 for EEG\n",
    "    data sampled at 250Hz. We instead use length 13 since the sampling rate is \n",
    "    roughly half of the 250Hz which the paper used. The pool_size and stride\n",
    "    in later layers is also approximately half of what is used in the paper.\n",
    "    \n",
    "    Note that we use the max_norm constraint on all convolutional layers, as \n",
    "    well as the classification layer. We also change the defaults for the\n",
    "    BatchNormalization layer. We used this based on a personal communication \n",
    "    with the original authors.\n",
    "    \n",
    "                     ours        original paper\n",
    "    pool_size        1, 35       1, 75\n",
    "    strides          1, 7        1, 15\n",
    "    conv filters     1, 13       1, 25    \n",
    "    \n",
    "    Note that this implementation has not been verified by the original \n",
    "    authors. We do note that this implementation reproduces the results in the\n",
    "    original paper with minor deviations. \n",
    "    \"\"\"\n",
    "\n",
    "    # start the model\n",
    "    input_main   = Input((Chans, Samples, 1))\n",
    "    block1       = Conv2D(40, (1, 13), \n",
    "                                 input_shape=(Chans, Samples, 1),\n",
    "                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n",
    "    block1       = Conv2D(40, (Chans, 1), use_bias=False, \n",
    "                          kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n",
    "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block1)\n",
    "    block1       = Activation(square)(block1)\n",
    "    block1       = AveragePooling2D(pool_size=(1, 35), strides=(1, 7))(block1)\n",
    "    block1       = Activation(log)(block1)\n",
    "    block1       = Dropout(dropoutRate)(block1)\n",
    "    flatten      = Flatten()(block1)\n",
    "    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n",
    "    softmax      = Activation('softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input_main, outputs=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### DNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "6Prm8UPC9Q4k"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Flatten,  Conv2D,BatchNormalization, AveragePooling2D, Dropout\n",
    "from tensorflow.keras.layers import SpatialDropout2D, Reshape\n",
    "from tensorflow.keras.optimizers import  Adamax\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "\n",
    "def gen_model_DNC( ): \n",
    "  \n",
    "    inp = tf.keras.Input(shape=(features,Channels,1))\n",
    "    c1 =Conv2D(30, (13, 1),kernel_regularizer=l2(0.001), kernel_constraint = max_norm(2., axis=(0,1,2)))(inp)\n",
    "    c2=Conv2D(30, (1, Channels ), use_bias=False, kernel_regularizer=l1_l2(l1=1e-5, l2=0.001), kernel_constraint = max_norm(2., axis=(0,1,2)))(c1)\n",
    "    bn=BatchNormalization(epsilon=1e-05, momentum=0.1)(c2)\n",
    "    ac1=Activation(square)(bn)\n",
    "    avg1= AveragePooling2D(pool_size=(100,1) , strides=(100, 1)  )(ac1)\n",
    "    ac2= Activation(log)(avg1)\n",
    "    sdout= SpatialDropout2D( 0.15 )(ac2)\n",
    "\n",
    "    shallowConvNet_dim1=9\n",
    "    shallowConvNet_dim2=30\n",
    "    rs=Reshape(( shallowConvNet_dim1 , shallowConvNet_dim2 ))(sdout)\n",
    "\n",
    "#     ----------------------------------  \n",
    "    x = tf.keras.Input(shape=(None, 30, ))\n",
    "    dnc_cell = DNC( \n",
    "      30,\n",
    "      controller_units=64,\n",
    "      memory_size=18,\n",
    "      word_size=8,\n",
    "      num_read_heads=2\n",
    "    )\n",
    "    dnc_initial_state = dnc_cell.get_initial_state(batch_size=512)\n",
    "    rnn = tf.keras.layers.RNN(dnc_cell, return_sequences=True)\n",
    "    rnn._name ='DNC_layer'\n",
    "    y = rnn( rs, initial_state=dnc_initial_state)\n",
    "#     ----------------------------------\n",
    "\n",
    "\n",
    "    fl=Flatten ()(y)\n",
    "    fc1 = Dense( 16 )(fl)\n",
    "    do = Dropout(0.3 )(fc1)\n",
    "    fc2 = Dense(2,activation='sigmoid')(do)\n",
    "    model55 = tf.keras.models.Model(inputs=inp, outputs= fc2)\n",
    "    \n",
    "    \n",
    "\n",
    "    opt=Adamax(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5)     \n",
    "    model55.compile(loss='binary_crossentropy', optimizer=opt,  metrics=['binary_accuracy'  , precision_m, recall_m, f1_m, sensitivity_m, specificity_m  ])\n",
    "    return model55\n",
    "\n",
    "b = gen_model_DNC()\n",
    "b.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "igSfgMLqu2Or"
   },
   "source": [
    "### Model_Maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "id": "OMSSjhNwu005"
   },
   "outputs": [],
   "source": [
    "def Model_Maker( ):  \n",
    "  \n",
    "\n",
    "  return gen_model_DNC() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "he6ydZETuYlR"
   },
   "source": [
    "## Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "id": "5OnFdmyIuXRr"
   },
   "outputs": [],
   "source": [
    "## Pipeline library\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "   \n",
    "def make_pipeline():    \n",
    "\n",
    "    main_pipeline = Pipeline(steps =[\n",
    "        ('scaler',StandardScaler() ),           \n",
    "        ('Reshaping' , CustomLSTMReshaper()),         \n",
    "        ('classifier', KerasClassifier(  build_fn=Model_Maker  , batch_size=512, verbose=1, epochs=700    ))       \n",
    "    ],  verbose=True )\n",
    "    \n",
    "    return main_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "SE44B-tSXD9d"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "id": "YMkgKQnVXHFA"
   },
   "outputs": [],
   "source": [
    "from plot_keras_history import plot_history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Visualize_Result(mp , k, path ,  dbType): \n",
    "\n",
    "  #pip install plot_keras_history\n",
    "  #https://pypi.org/project/plot-keras-history/\n",
    "\n",
    "  estimator= mp['classifier'] \n",
    "  history=estimator.model.history.history\n",
    "\n",
    "\n",
    "  # plot_history(history)\n",
    "  # plt.show()\n",
    "\n",
    "  plot_history(history, path= path + dbType +\"_\"+ \"_fold(\"+ str(k) +\").png\" )\n",
    "  plt.close()\n",
    "  return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "J-hSY5oGoC2s"
   },
   "source": [
    "# post_Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true,
    "id": "WM3KGj50Z2Ud"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from matplotlib import pyplot as pl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def dict_mean(dict_list):\n",
    "  mean_dict = {}\n",
    "  std_dict = {}\n",
    "  \n",
    "\n",
    "  for key in dict_list[0].keys():\n",
    "      mean_dict[key] = np.mean([d[key] for d in dict_list], axis=0)\n",
    "      std_dict[key] = np.std([d[key] for d in dict_list], axis=0)\n",
    "  \n",
    "  return mean_dict, std_dict\n",
    "\n",
    "\n",
    "j=0 \n",
    "\n",
    "def Auto_All_History_plot(all_history, savepath , dbType):\n",
    "  #print(  all_history  )\n",
    "  result=dict_mean(all_history )\n",
    "  \n",
    "  print()\n",
    "  for val_metric_name in result[0]:\n",
    "    #print('key', val_metric_name )\n",
    "    \n",
    "    if str( val_metric_name[0:4]) !='val_': # This is a condition for not calculating the results for both train and validation categories\n",
    "        #break                               # Calculations are performed for train category and evaluation is also considered for validation\n",
    "        continue\n",
    "        \n",
    "         \n",
    "    metric_name=str( val_metric_name[4:])\n",
    "\n",
    "\n",
    "    mean=result[0][ metric_name ] # mean\n",
    "    std=result[1][ metric_name ] #std\n",
    "\n",
    "\n",
    "    val_mean=result[0][ val_metric_name ] # mean\n",
    "    val_std=result[1][ val_metric_name ] #std\n",
    "\n",
    "\n",
    "    pl.plot(mean ,color='blue' , marker=\"x\", markersize=10 ,markevery=70  )  \n",
    "    pl.plot(val_mean ,color='red'  ,linestyle='dashed', markersize=20 )\n",
    "\n",
    "    pl.fill_between(  range(len(mean)) , mean-std, mean + std , alpha=0.3, label='Train' ,color='blue' )\n",
    "    pl.fill_between(  range(len(val_mean)) , val_mean-val_std, val_mean + val_std , alpha=0.3 , label='Validation' ,color='red' )\n",
    "\n",
    "    if str( metric_name[-2:] )=='_m':\n",
    "        metric_name=metric_name[:-2]\n",
    "    \n",
    "\n",
    "    plt.title( 'The Model '+metric_name+' Plot')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel( metric_name )\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    #pl.show()\n",
    "    plt.savefig( savepath+dbType+ '_'+ metric_name+'.png')\n",
    "    plt.close()\n",
    "\n",
    "  return\n",
    "Auto_All_History_plot( all_history , basePath ,dbType)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "fz35La2wB_E_"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "id": "h9__qqxhVXWx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 123\n"
     ]
    }
   ],
   "source": [
    "# test Unseen data\n",
    "import pickle as pkl\n",
    "\n",
    "def LoadUnseenData():\n",
    "  \n",
    "  with open(basePath+'Imagery_temp_X_test_IV2A.pkl','rb') as f: #read\n",
    "    X_test = pkl.load(f)\n",
    "    \n",
    "  #print(X_test.shape)\n",
    "  \n",
    "\n",
    "  with open(basePath+'Imagery_temp_y_test_IV2A.pkl','rb') as f: #read\n",
    "    Y_test = pkl.load(f)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Y_test=[np.where(r==1)[0][0] for r in Y_test]\n",
    "    \n",
    "  #print(Y_test.shape)\n",
    "  print('-------------------------------------------')\n",
    "\n",
    "  return X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "U-m8GMo1CToC"
   },
   "source": [
    "# over_all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true,
    "id": "Elooi83OJjD7"
   },
   "outputs": [],
   "source": [
    "def over_all_metrics_stat(skf_metrics, savePath):\n",
    "  # Take mean and std over all folds \n",
    "  average_metrics_all_folds = dict(pd.DataFrame(skf_metrics).mean())\n",
    "  std_metrics_all_folds = dict(pd.DataFrame(skf_metrics).std())\n",
    "\n",
    "  \n",
    "\n",
    "  average_metrics_all_folds = {str( k[5:])+\"_avg_folds\":v for k,v in average_metrics_all_folds.items()}\n",
    "  std_metrics_all_folds = {str( k[5:])+\"_std_folds\":v for k,v in std_metrics_all_folds.items()}\n",
    "\n",
    "  print('_________ Training metric for all k-fold _________')\n",
    "  print('average_metrics_all_folds')\n",
    "  print(average_metrics_all_folds)\n",
    "  print()\n",
    "  print('std_metrics_all_folds')    \n",
    "  print(std_metrics_all_folds)\n",
    "  print()\n",
    "\n",
    "\n",
    "  df_average_metrics_all_folds = pd.DataFrame([average_metrics_all_folds])\n",
    "  df_std_metrics_all_folds = pd.DataFrame([std_metrics_all_folds])\n",
    "\n",
    "  pd.concat([df_average_metrics_all_folds, df_std_metrics_all_folds ],axis=1 ).to_csv( savePath + dbType + '_UnSeen_data_metric_avg_std.csv')\n",
    "\n",
    "\n",
    "  return     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "qdRHc9ewBXdn"
   },
   "source": [
    "# k-fold Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "_8GcYyOfmQzF",
    "outputId": "6655fe2f-7199-433c-ce4c-da0eecaa1258"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits=5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=False ) #,random_state=random_seed\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "folds = {}\n",
    "count = 1\n",
    "for train_index, val_index in skf.split(X_train, y_train2 ):\n",
    "    folds['fold_{}'.format(count)] = {}\n",
    "    folds['fold_{}'.format(count)]['train_index'] = train_index.tolist()\n",
    "    folds['fold_{}'.format(count)]['val_index'] = val_index.tolist()\n",
    "    count += 1\n",
    "print(len(folds) == n_splits)#assert we have the same number of splits\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "yCLhu9U9o042"
   },
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ RUN ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "import pandas as pd\n",
    "import gc\n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i=1\n",
    " \n",
    "for key, val in folds.items():\n",
    "\n",
    "\n",
    "  print(key)\n",
    "  print(i)\n",
    "\n",
    "  train_index = val['train_index']\n",
    "  val_index = val['val_index']\n",
    "\n",
    "\n",
    "  \n",
    "  skf_X_train, skf_X_val = (pd.DataFrame( X_train )).iloc[train_index], (pd.DataFrame( X_train)).iloc[val_index]\n",
    "  skf_y_train, skf_y_val = (pd.DataFrame( y_train2 )).iloc[train_index], (pd.DataFrame( y_train2 )).iloc[val_index]\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "  with open( basePath + 'kfold_data_variable ('+ str(i) +').pkl', 'wb') as p: \n",
    "      pickle.dump([ skf_X_train, skf_X_val, skf_y_train, skf_y_val  ], p)\n",
    "\n",
    "\n",
    "  print('_step_',i)\n",
    "  i+=1\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "zl31eNvfBbD1"
   },
   "source": [
    "# k-fold Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "xu7j-71qH7E3",
    "outputId": "23af0b44-5f21-4665-fd4d-4328c53fc42c"
   },
   "outputs": [],
   "source": [
    "# load previous config\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "try:\n",
    "  with open(basePath + dbType +'_Kfold_Imagery_all_history.pkl','rb') as f: #read\n",
    "    all_history = pkl.load(f)\n",
    "\n",
    "  with open(basePath + dbType+ '_UnSeen_data_metric_avg_std.pkl','rb') as f: #read\n",
    "    skf_metrics = pkl.load(f)\n",
    "\n",
    "\n",
    "except:\n",
    "  print('var empty mod')\n",
    "  all_history= []\n",
    "  skf_metrics= []\n",
    " \n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNOpWwyZD0xF"
   },
   "source": [
    "# Main Excutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oZYGO1J0yKhG",
    "outputId": "fb7cd500-ccf6-4fae-f445-b1aa0d943b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(all_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JI9dq7aTqM1m",
    "outputId": "f0dcd4c5-8386-4375-e7a9-e1a219540eb4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ RUN ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "import pandas as pd\n",
    "import gc\n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "i=5\n",
    "\n",
    "\n",
    "with open( basePath + 'kfold_data_variable ('+ str( i) +').pkl' ,'rb') as p:   \n",
    "    skf_X_train, skf_X_val, skf_y_train, skf_y_val  = pickle.load(p)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "print(\"============ Training on fold ({}) ==============\".format(i))\n",
    "\n",
    "#skf_y_val2=[np.where(r==1)[0][0] for r in np.array(skf_y_val) ]\n",
    "\n",
    "\n",
    "skf_y_train2= to_categorical( skf_y_train , num_classes=2)\n",
    "skf_y_val2= to_categorical( skf_y_val , num_classes=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeline = make_pipeline( ) \n",
    "\n",
    "# ------------------------\n",
    "pipeline.named_steps['scaler'].fit(skf_X_train)\n",
    "skf_X_val22=pipeline.named_steps['scaler'].transform(skf_X_val)\n",
    "skf_X_val2=pipeline.named_steps['Reshaping'].transform(skf_X_val22)\n",
    "# ------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pipeline.fit(skf_X_train, skf_y_train2 , classifier__validation_data=( skf_X_val2, skf_y_val2)  )\n",
    "\n",
    "gc.collect()\n",
    "del skf_X_train, skf_y_train, skf_y_val, skf_y_train2, skf_y_val2, skf_X_val2, skf_X_val22, skf_X_val\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test, Y_test =LoadUnseenData()\n",
    "\n",
    "y_pred_val = pipeline.predict( X_test  )\n",
    "del X_test\n",
    "gc.collect()\n",
    "\n",
    "print(\"_________________________________________________\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('___step___',i)\n",
    "print()\n",
    "print('Model Evaluation is in process...')\n",
    "test_results = get_experiments( Y_test , y_pred_val)\n",
    "print(test_results)\n",
    "del Y_test , y_pred_val\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "skf_metrics.append(test_results)\n",
    "\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "all_history.append( pipeline['classifier'].model.history.history )\n",
    "print('Model Training history has been store')\n",
    "print()\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "Visualize_Result(pipeline , i, basePath ,   dbType )\n",
    "print('Evaluation Resault has been Visualized')\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "# # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "del pipeline\n",
    "gc.collect()\n",
    "\n",
    "# # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "with open(basePath + dbType +'_Kfold_Imagery_all_history.pkl','wb') as f: #write\n",
    "  pkl.dump( all_history , f)\n",
    "print('Model Training history Resault has been wrote on file')\n",
    "\n",
    "\n",
    "with open(basePath + dbType +'_UnSeen_data_metric_avg_std.pkl','wb') as f: #write\n",
    "  pkl.dump( skf_metrics , f)\n",
    "print('Model Evaliuation Resault has been wrote on file')  \n",
    "\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_history))\n",
    "#all_history.append( pipeline['classifier'].model.history.history )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-oTLcvLGYBH"
   },
   "outputs": [],
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# get results\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# pd.DataFrame([skf_metrics]).to_csv( basePath+ dbType + '_All_fold_Results_Metric.csv')\n",
    "\n",
    "over_all_metrics_stat(skf_metrics, basePath)\n",
    "\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "pd.DataFrame([all_history]).to_csv( basePath+ dbType+'_All_history.csv')\n",
    "\n",
    "Auto_All_History_plot( all_history , basePath ,dbType)\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# pd.DataFrame([all_UnseenData_results]).to_csv( basePath+ dbType + '_All_UnseenData_Results.csv')\n",
    "\n",
    "df = pd.DataFrame( skf_metrics, columns=['test_accuracy', 'test_precision', 'test_recall' ,'test_f1' , 'test_specificity', 'test_sensitivity', 'test_kappa' ])\n",
    "pd.DataFrame( df ).to_csv( basePath + dbType + '_All_UnseenData_Results_df.csv' , index=False )\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "\n",
    "print(' ok ')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1EODUBQj-zPU",
    "h11kVYItZ-qn",
    "aTb_J9rhuBs6",
    "JiZUQk7CYqN0",
    "Fjo7iI5D3Rt8",
    "igSfgMLqu2Or",
    "he6ydZETuYlR",
    "SE44B-tSXD9d",
    "J-hSY5oGoC2s",
    "fz35La2wB_E_",
    "U-m8GMo1CToC",
    "qdRHc9ewBXdn",
    "zl31eNvfBbD1",
    "Oi-Bnq7kKj6B"
   ],
   "name": "TDNTM_IV2A_Imagery_14000720.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
